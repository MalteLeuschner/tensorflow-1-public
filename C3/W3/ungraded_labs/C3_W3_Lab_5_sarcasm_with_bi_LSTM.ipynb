{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C3/W3/ungraded_labs/C3_W3_Lab_5_sarcasm_with_bi_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2MY4-M1zuhV"
   },
   "source": [
    "# Ungraded Lab: Training a Sarcasm Detection Model using Bidirectional LSTMs\n",
    "\n",
    "In this lab, you will revisit the [News Headlines Dataset for Sarcasm Detection](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection/home) dataset and use it to train a Bi-LSTM Model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-AgItE6z80t"
   },
   "source": [
    "## Download the Dataset\n",
    "\n",
    "First, you will download the JSON file and extract the contents into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "k_Wlz9i10Dmn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-01 13:59:13--  https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:4001:80e::2010, 2a00:1450:4001:80b::2010, 2a00:1450:4001:809::2010, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:4001:80e::2010|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 5643545 (5.4M) [application/json]\r\n",
      "Saving to: ‘sarcasm.json’\r\n",
      "\r\n",
      "sarcasm.json        100%[===================>]   5.38M  6.35MB/s    in 0.8s    \r\n",
      "\r\n",
      "2022-12-01 13:59:14 (6.35 MB/s) - ‘sarcasm.json’ saved [5643545/5643545]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "!wget https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Pr4R0I240GOh"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"./sarcasm.json\", 'r') as f:\n",
    "    datastore = json.load(f)\n",
    "\n",
    "# Initialize the lists\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "# Collect sentences and labels into the lists\n",
    "for item in datastore:\n",
    "    sentences.append(item['headline'])\n",
    "    labels.append(item['is_sarcastic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zN9-ojV55UCR"
   },
   "source": [
    "## Split the Dataset\n",
    "\n",
    "You will then split the lists into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "50H0ZrJf035i"
   },
   "outputs": [],
   "source": [
    "training_size = 20000\n",
    "\n",
    "# Split the sentences\n",
    "training_sentences = sentences[0:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "\n",
    "# Split the labels\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYVNY4tE5YbN"
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Next, you will generate the vocabulary and padded sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hodsUZib1Ce7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 10000\n",
    "max_length = 120\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "# Initialize the Tokenizer class\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "\n",
    "# Generate the word index dictionary\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Generate and pad the training sequences\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "# Generate and pad the testing sequences\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "# Convert the labels lists into numpy arrays\n",
    "training_labels = np.array(training_labels)\n",
    "testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o23gJhj95el5"
   },
   "source": [
    "## Build and Compile the Model\n",
    "\n",
    "The architecture here is almost identical to the one you used in the previous lab with the IMDB Reviews. Try to tweak the parameters and see how it affects the training time and accuracy (both training and validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jGwXGIXvFhXW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 13:59:26.132992: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 13:59:26.147438: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 120, 16)           160000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               12544     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 174,129\n",
      "Trainable params: 174,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "embedding_dim = 16\n",
    "lstm_dim = 32\n",
    "dense_dim = 24\n",
    "\n",
    "# Model Definition with LSTM\n",
    "model_lstm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_dim)),\n",
    "    tf.keras.layers.Dense(dense_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Set the training parameters\n",
    "model_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krcQGm7B5g9A"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "nEKV8EMj11BW",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 120s 188ms/step - loss: 0.4122 - accuracy: 0.7943 - val_loss: 0.3460 - val_accuracy: 0.8457\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 124s 199ms/step - loss: 0.2207 - accuracy: 0.9093 - val_loss: 0.3407 - val_accuracy: 0.8506\n",
      "Epoch 3/10\n",
      "340/625 [===============>..............] - ETA: 45s - loss: 0.1296 - accuracy: 0.9510"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Train the model\n",
    "history_lstm = model_lstm.fit(training_padded, training_labels, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9DC6dmLF8DC"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Utility\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "\n",
    "# Plot the accuracy and loss history\n",
    "plot_graphs(history_lstm, 'accuracy')\n",
    "plot_graphs(history_lstm, 'loss')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C3_W3_Lab_5_sarcasm_with_bi_LSTM.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
